{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "residential-world",
   "metadata": {},
   "source": [
    "# Introducción Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-american",
   "metadata": {},
   "source": [
    "![elgifderigor](https://media.giphy.com/media/NsBknNwmmWE8WU1q2U/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-vault",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Algunos-conceptos\" data-toc-modified-id=\"Algunos-conceptos-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Algunos conceptos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Estimadores\" data-toc-modified-id=\"Estimadores-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Estimadores</a></span></li><li><span><a href=\"#Error-de-Bias\" data-toc-modified-id=\"Error-de-Bias-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Error de Bias (Sesgo)</a></span></li><li><span><a href=\"#Error-de-Varianza\" data-toc-modified-id=\"Error-de-Varianza-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Error de Varianza</a></span></li></ul></li><li><span><a href=\"#Tipos-de-Aprendizaje-Automático\" data-toc-modified-id=\"Tipos-de-Aprendizaje-Automático-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Tipos de Aprendizaje Automático</a></span></li><li><span><a href=\"#Features\" data-toc-modified-id=\"Features-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Features</a></span></li><li><span><a href=\"#Underfitting-y-Overfitting\" data-toc-modified-id=\"Underfitting-y-Overfitting-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Underfitting y Overfitting</a></span></li><li><span><a href=\"#¿Manos-a-la-obra?\" data-toc-modified-id=\"¿Manos-a-la-obra?-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>¿Manos a la obra?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Practicamos-ML-con-un-ejemplo-de-regresión\" data-toc-modified-id=\"Practicamos-ML-con-un-ejemplo-de-regresión-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Practicamos ML con un ejemplo de regresión</a></span></li><li><span><a href=\"#Cargamos-un-dataset-(aunque-ya-nos-resulta-famliar)\" data-toc-modified-id=\"Cargamos-un-dataset-(aunque-ya-nos-resulta-famliar)-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Cargamos un dataset (aunque ya nos resulta famliar)</a></span></li><li><span><a href=\"#Train-/-Test-Split-¿Esto-qué-es?\" data-toc-modified-id=\"Train-/-Test-Split-¿Esto-qué-es?-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Train / Test Split ¿Esto qué es?</a></span></li><li><span><a href=\"#Preparación-de-los-datos-para-train-test-split\" data-toc-modified-id=\"Preparación-de-los-datos-para-train-test-split-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Preparación de los datos para train test split</a></span></li><li><span><a href=\"#Parámetros-opcionales-del-train-test-split\" data-toc-modified-id=\"Parámetros-opcionales-del-train-test-split-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Parámetros opcionales del train test split</a></span></li><li><span><a href=\"#Ya-tenemos-el-dataset-dividido,-ahora-vamos-a-importar-un-modelo-y-entrenarlo\" data-toc-modified-id=\"Ya-tenemos-el-dataset-dividido,-ahora-vamos-a-importar-un-modelo-y-entrenarlo-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Ya tenemos el dataset dividido, ahora vamos a importar un modelo y entrenarlo</a></span></li><li><span><a href=\"#Creamos-nuestras-predicciones\" data-toc-modified-id=\"Creamos-nuestras-predicciones-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;</span>Creamos nuestras predicciones</a></span></li><li><span><a href=\"#Medimos-nuestro-modelo\" data-toc-modified-id=\"Medimos-nuestro-modelo-5.8\"><span class=\"toc-item-num\">5.8&nbsp;&nbsp;</span>Medimos nuestro modelo</a></span></li></ul></li><li><span><a href=\"#Extra!-Entrenando-diferentes-modelos-a-la-vez\" data-toc-modified-id=\"Extra!-Entrenando-diferentes-modelos-a-la-vez-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Extra! Entrenando diferentes modelos a la vez</a></span><ul class=\"toc-item\"><li><span><a href=\"#Almacenamos-todos-los-modelos-que-vamos-a-entrenar-en-un-diccionario\" data-toc-modified-id=\"Almacenamos-todos-los-modelos-que-vamos-a-entrenar-en-un-diccionario-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Almacenamos todos los modelos que vamos a entrenar en un diccionario</a></span></li><li><span><a href=\"#Iteramos-sobre-los-modelos-para-entrenarlos\" data-toc-modified-id=\"Iteramos-sobre-los-modelos-para-entrenarlos-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Iteramos sobre los modelos para entrenarlos</a></span></li></ul></li><li><span><a href=\"#Cross-Validation\" data-toc-modified-id=\"Cross-Validation-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Cross-Validation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hacemos-CV-a-un-solo-modelo\" data-toc-modified-id=\"Hacemos-CV-a-un-solo-modelo-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Hacemos CV a un solo modelo</a></span></li><li><span><a href=\"#CV-iterando-por-todos-los-modelos\" data-toc-modified-id=\"CV-iterando-por-todos-los-modelos-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>CV iterando por todos los modelos</a></span></li></ul></li><li><span><a href=\"#Summmary\" data-toc-modified-id=\"Summmary-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Summmary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-pharmaceutical",
   "metadata": {},
   "source": [
    "## Algunos conceptos\n",
    "Para entender cómo un algoritmo de aprendizaje automático aprende de los datos para predecir un resultado, es esencial comprender los conceptos subyacentes que intervienen en el entrenamiento de un algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-aquatic",
   "metadata": {},
   "source": [
    "### Estimadores\n",
    "La estimación es un término estadístico para encontrar alguna estimación de un parámetro desconocido, dados algunos datos. La estimación puntual es el intento de proporcionar la mejor predicción de alguna cantidad de interés.\n",
    "La cantidad de interés puede ser: \n",
    " - Un único parámetro\n",
    " - Un vector de parámetros - por ejemplo, los pesos en la regresión lineal \n",
    " - Una función completa\n",
    "\n",
    "### Error de Bias (Sesgo)\n",
    "\n",
    "Es la diferencia entre la predicción esperada de nuestro modelo y los valores verdaderos. Aunque al final nuestro objetivo es siempre construir modelos que puedan predecir datos muy cercanos a los valores verdaderos, no siempre es tan fácil porque algunos algoritmos son simplemente demasiado rígidos para aprender señales complejas del conjunto de datos.\n",
    "\n",
    "Imagina ajustar una regresión lineal a un conjunto de datos que tiene un patrón no lineal, no importa cuántas observaciones más recopiles, una regresión lineal no podrá modelar las curvas en esos datos. Esto se conoce como ajuste insuficiente.\n",
    "\n",
    "En general, los algoritmos paramétricos como la regresión lineal, tienen un alto bias que los hace rápidos de aprender y más fácil de entender, pero generalmente menos flexibles. A su vez, tienen un menor rendimiento predictivo en problemas complejos.\n",
    "\n",
    "### Error de Varianza\n",
    "\n",
    "Se refiere a la cantidad que la estimación de la función objetivo cambiará si se utiliza diferentes datos de entrenamiento. La función objetivo se estima a partir de los datos de entrenamiento mediante un algoritmo de Machine Learning, por lo que deberíamos esperar que el algoritmo tenga alguna variación. Idealmente no debería cambiar demasiado de un conjunto de datos de entrenamiento a otro, lo que significa que el algoritmo es bueno para elegir el mapeo subyacente oculto entre las variables de entrada y de salida.\n",
    "\n",
    "Los algoritmos de Machine Learning que tienen una gran varianza están fuertemente influenciados por los detalles de los datos de entrenamiento, esto significa que los detalles de la capacitación influyen en el número y los tipos de parámetros utilizados para caracterizar la función de mapeo.\n",
    "\n",
    "Generalmente, los algoritmos de Machine Learning no paramétrico que tienen mucha flexibilidad tienen una gran variación.\n",
    "\n",
    "- Varianza baja: sugiere pequeños cambios en la estimación de la función objetivo con cambios en el conjunto de datos de capacitación.\n",
    "- Alta varianza: sugiere grandes cambios en la estimación de la función objetivo con cambios en el conjunto de datos de capacitación.\n",
    "Los algoritmos de Machine Learning con baja varianza incluyen: regresión lineal, análisis discriminante lineal y regresión logística.\n",
    "\n",
    "Por su parte, los algoritmos con alta varianza son: árboles de decisión, k-vecinos más cercanos y máquinas de vectores de soporte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee9c76",
   "metadata": {},
   "source": [
    "<img src=\"https://nvsyashwanth.github.io/machinelearningmaster/assets/images/bias_variance.jpg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-intro",
   "metadata": {},
   "source": [
    "## Tipos de Aprendizaje Automático\n",
    "**- Supervisado**      \n",
    "El modelo se entrena con datos etiquetados, es decir, con datos cuya verdad básica se conoce. Cuando se le presentan datos y una etiqueta, el modelo infiere patrones.      \n",
    "**- No supervisado**          \n",
    "No hay verdades básicas. El modelo busca patrones no detectados previamente, con los que separar los distintos puntos de datos en diferentes clusters.\n",
    "**- Refuerzo**    \n",
    "Tampoco existe una verdad de base. La acción del modelo se valora y se da una recompensa o un castigo en consecuencia. El objetivo del modelo es obtener el mayor número de recompensas posible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-bobby",
   "metadata": {},
   "source": [
    "## Features\n",
    "Las **Features** son variables individuales independientes que actúan como entrada en su sistema. Los modelos de predicción utilizan características para\n",
    "hacer predicciones.      \n",
    "**Objetivo**        \n",
    "El objetivo es la salida de las variables de entrada. Pueden ser las clases individuales a las que se asignan las variables de entrada en el caso de un problema de clasificación o el rango de valores de salida en un problema de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-nelson",
   "metadata": {},
   "source": [
    "## Underfitting y Overfitting  \n",
    "Dividir un conjunto de datos también puede ser importante para detectar si su modelo sufre uno de los dos problemas más comunes, denominados infraajuste y sobreajuste:\n",
    "\n",
    "El **underfitting** suele ser la consecuencia de que un modelo sea incapaz de encapsular las relaciones entre los datos. Por ejemplo, esto puede ocurrir cuando se intenta representar relaciones no lineales con un modelo lineal. Los modelos infraajustados probablemente tendrán un rendimiento pobre tanto en los conjuntos de entrenamiento como en los de prueba.\n",
    "\n",
    "El **overfitting** suele tener lugar cuando un modelo tiene una estructura excesivamente compleja y aprende tanto las relaciones existentes entre los datos como el ruido. Estos modelos suelen tener una mala capacidad de generalización. Aunque funcionan bien con los datos de entrenamiento, suelen tener un rendimiento pobre con los datos no vistos (de prueba)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42891daf",
   "metadata": {},
   "source": [
    "<img src=\"https://community.alteryx.com/t5/image/serverpage/image-id/52874iE986B6E19F3248CF?v=v2\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-apparel",
   "metadata": {},
   "source": [
    "## ¿Manos a la obra?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-jackson",
   "metadata": {},
   "source": [
    "### Practicamos ML con un ejemplo de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "legitimate-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-reconstruction",
   "metadata": {},
   "source": [
    "### Cargamos un dataset (aunque ya nos resulta famliar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29aba32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_boston in module sklearn.datasets._base:\n",
      "\n",
      "load_boston(*, return_X_y=False)\n",
      "    Load and return the boston house-prices dataset (regression).\n",
      "    \n",
      "    ==============   ==============\n",
      "    Samples total               506\n",
      "    Dimensionality               13\n",
      "    Features         real, positive\n",
      "    Targets           real 5. - 50.\n",
      "    ==============   ==============\n",
      "    \n",
      "    Read more in the :ref:`User Guide <boston_dataset>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    return_X_y : bool, default=False.\n",
      "        If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "        See below for more information about the `data` and `target` object.\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    data : :class:`~sklearn.utils.Bunch`\n",
      "        Dictionary-like object, with the following attributes.\n",
      "    \n",
      "        data : ndarray of shape (506, 13)\n",
      "            The data matrix.\n",
      "        target : ndarray of shape (506, )\n",
      "            The regression target.\n",
      "        filename : str\n",
      "            The physical location of boston csv dataset.\n",
      "    \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "        DESCR : str\n",
      "            The full description of the dataset.\n",
      "        feature_names : ndarray\n",
      "            The names of features\n",
      "    \n",
      "    (data, target) : tuple if ``return_X_y`` is True\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "        .. versionchanged:: 0.20\n",
      "            Fixed a wrong data point at [445, 0].\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.datasets import load_boston\n",
      "    >>> X, y = load_boston(return_X_y=True)\n",
      "    >>> print(X.shape)\n",
      "    (506, 13)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(load_boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b461bd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_boston()['DESCR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "respiratory-elite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston=pd.DataFrame(load_boston().data, columns=load_boston().feature_names)\n",
    "\n",
    "boston['MEDV']=load_boston().target\n",
    "\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-bacteria",
   "metadata": {},
   "source": [
    "### Train / Test Split ¿Esto qué es?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e15f7",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/kaggle_train_test_split.svg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-grove",
   "metadata": {},
   "source": [
    "La división entrenamiento-prueba es una técnica para evaluar el rendimiento de un algoritmo de aprendizaje automático.\n",
    "\n",
    "Puede utilizarse para problemas de clasificación o regresión y puede emplearse para cualquier algoritmo de aprendizaje supervisado.\n",
    "\n",
    "El procedimiento consiste en tomar un conjunto de datos y dividirlo en dos subconjuntos. El primer subconjunto se utiliza para ajustar el modelo y se denomina conjunto de datos de entrenamiento. El segundo subconjunto no se utiliza para entrenar el modelo; en su lugar, se proporciona al modelo el elemento de entrada del conjunto de datos, luego se hacen predicciones y se comparan con los valores esperados. Este segundo conjunto de datos se denomina conjunto de datos de prueba.\n",
    "\n",
    "Conjunto de datos de entrenamiento: Se utiliza para ajustar el modelo de aprendizaje automático.\n",
    "Conjunto de datos de prueba: Se utiliza para evaluar el modelo de aprendizaje automático ajustado.\n",
    "El objetivo es estimar el rendimiento del modelo de aprendizaje automático con datos nuevos: datos no utilizados para entrenar el modelo.\n",
    "\n",
    "Así es como esperamos utilizar el modelo en la práctica. Es decir, ajustarlo sobre los datos disponibles con entradas y salidas conocidas, para luego hacer predicciones sobre nuevos ejemplos en el futuro en los que no tenemos los valores de salida u objetivo esperados.\n",
    "\n",
    "El procedimiento de entrenamiento-prueba es adecuado cuando se dispone de un conjunto de datos suficientemente amplio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-texas",
   "metadata": {},
   "source": [
    "### Preparación de los datos para train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "automatic-adoption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT', 'MEDV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "seasonal-lincoln",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=boston.drop('MEDV', axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sealed-realtor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24.0\n",
       "1    21.6\n",
       "2    34.7\n",
       "3    33.4\n",
       "4    36.2\n",
       "Name: MEDV, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=boston.MEDV\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "closed-wellington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "intensive-newark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-musician",
   "metadata": {},
   "source": [
    "### Parámetros opcionales del train test split\n",
    "\n",
    "**train_size** es el número que define el tamaño del conjunto de entrenamiento. Si proporciona un float, entonces debe estar entre 0.0 y 1.0 y definirá la parte del conjunto de datos utilizado para las pruebas. Si proporciona un int, entonces representará el número total de las muestras de entrenamiento. El valor por defecto es None.\n",
    "\n",
    "**test_size** es el número que define el tamaño del conjunto de pruebas. Es muy similar a train_size. Debe proporcionar o bien train_size o bien test_size. Si no se proporciona ninguno de los dos, la parte por defecto del conjunto de datos que se utilizará para las pruebas es 0,25, o el 25 por ciento.\n",
    "\n",
    "**random_state** es el objeto que controla la aleatoriedad durante la división. Puede ser un int o una instancia de RandomState. El valor por defecto es None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "private-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4aeb0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, **options)\n",
      "    Split arrays or matrices into random train and test subsets\n",
      "    \n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int or RandomState instance, default=None\n",
      "        Controls the shuffling applied to the data before applying the split.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    \n",
      "    shuffle : bool, default=True\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like, default=None\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hybrid-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "flying-alpha",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "comic-brown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "destroyed-velvet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "digital-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-defense",
   "metadata": {},
   "source": [
    "### Ya tenemos el dataset dividido, ahora vamos a importar un modelo y entrenarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ultimate-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as LinReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "manual-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo\n",
    "\n",
    "linreg=LinReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42c0a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7019bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion(*args):\n",
    "    print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86e31d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 4, 5, 6, 7)\n"
     ]
    }
   ],
   "source": [
    "funcion(3, 3, 4, 5, 6, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60f3c62d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LinearRegression in module sklearn.linear_model._base object:\n",
      "\n",
      "class LinearRegression(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, LinearModel)\n",
      " |  LinearRegression(*, fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
      " |  \n",
      " |  Ordinary least squares Linear Regression.\n",
      " |  \n",
      " |  LinearRegression fits a linear model with coefficients w = (w1, ..., wp)\n",
      " |  to minimize the residual sum of squares between the observed targets in\n",
      " |  the dataset, and the targets predicted by the linear approximation.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  fit_intercept : bool, default=True\n",
      " |      Whether to calculate the intercept for this model. If set\n",
      " |      to False, no intercept will be used in calculations\n",
      " |      (i.e. data is expected to be centered).\n",
      " |  \n",
      " |  normalize : bool, default=False\n",
      " |      This parameter is ignored when ``fit_intercept`` is set to False.\n",
      " |      If True, the regressors X will be normalized before regression by\n",
      " |      subtracting the mean and dividing by the l2-norm.\n",
      " |      If you wish to standardize, please use\n",
      " |      :class:`sklearn.preprocessing.StandardScaler` before calling ``fit`` on\n",
      " |      an estimator with ``normalize=False``.\n",
      " |  \n",
      " |  copy_X : bool, default=True\n",
      " |      If True, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to use for the computation. This will only provide\n",
      " |      speedup for n_targets > 1 and sufficient large problems.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : array of shape (n_features, ) or (n_targets, n_features)\n",
      " |      Estimated coefficients for the linear regression problem.\n",
      " |      If multiple targets are passed during the fit (y 2D), this\n",
      " |      is a 2D array of shape (n_targets, n_features), while if only\n",
      " |      one target is passed, this is a 1D array of length n_features.\n",
      " |  \n",
      " |  rank_ : int\n",
      " |      Rank of matrix `X`. Only available when `X` is dense.\n",
      " |  \n",
      " |  singular_ : array of shape (min(X, y),)\n",
      " |      Singular values of `X`. Only available when `X` is dense.\n",
      " |  \n",
      " |  intercept_ : float or array of shape (n_targets,)\n",
      " |      Independent term in the linear model. Set to 0.0 if\n",
      " |      `fit_intercept = False`.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  sklearn.linear_model.Ridge : Ridge regression addresses some of the\n",
      " |      problems of Ordinary Least Squares by imposing a penalty on the\n",
      " |      size of the coefficients with l2 regularization.\n",
      " |  sklearn.linear_model.Lasso : The Lasso is a linear model that estimates\n",
      " |      sparse coefficients with l1 regularization.\n",
      " |  sklearn.linear_model.ElasticNet : Elastic-Net is a linear regression\n",
      " |      model trained with both l1 and l2 -norm regularization of the\n",
      " |      coefficients.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  From the implementation point of view, this is just plain Ordinary\n",
      " |  Least Squares (scipy.linalg.lstsq) wrapped as a predictor object.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.linear_model import LinearRegression\n",
      " |  >>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
      " |  >>> # y = 1 * x_0 + 2 * x_1 + 3\n",
      " |  >>> y = np.dot(X, np.array([1, 2])) + 3\n",
      " |  >>> reg = LinearRegression().fit(X, y)\n",
      " |  >>> reg.score(X, y)\n",
      " |  1.0\n",
      " |  >>> reg.coef_\n",
      " |  array([1., 2.])\n",
      " |  >>> reg.intercept_\n",
      " |  3.0000...\n",
      " |  >>> reg.predict(np.array([[3, 5]]))\n",
      " |  array([16.])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LinearRegression\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      LinearModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training data\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
      " |          Target values. Will be cast to X's dtype if necessary\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Individual weights for each sample\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             parameter *sample_weight* support to LinearRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns an instance of self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a\n",
      " |          precomputed kernel matrix or a list of generic objects instead,\n",
      " |          shape = (n_samples, n_samples_fitted),\n",
      " |          where n_samples_fitted is the number of\n",
      " |          samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The R2 score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(linreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "small-sessions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47e6e4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.04101801e-01,  4.46607962e-02,  1.47975466e-02,  2.12950789e+00,\n",
       "       -1.70202488e+01,  3.74872759e+00, -2.72114100e-03, -1.51129780e+00,\n",
       "        3.05960473e-01, -1.28097230e-02, -9.72068358e-01,  9.64014122e-03,\n",
       "       -5.16032791e-01])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cae2e97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.19855220843748"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-migration",
   "metadata": {},
   "source": [
    "### Creamos nuestras predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "executed-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "single-johnson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.63062051, 24.5005557 , 13.71216264, 25.03316715, 14.22425052,\n",
       "       22.42972766, 13.83880621, 20.20222564, 31.87425281, 25.22986847])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4771f524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8      16.5\n",
       "100    27.5\n",
       "408    17.2\n",
       "347    23.1\n",
       "428    11.0\n",
       "270    21.1\n",
       "138    13.3\n",
       "393    13.8\n",
       "369    50.0\n",
       "375    15.0\n",
       "Name: MEDV, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73b9f3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e4077a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-imaging",
   "metadata": {},
   "source": [
    "### Medimos nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "treated-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ordered-nickel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MAE - Error Medio Absoluto', 3.0041718431725455)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'MAE - Error Medio Absoluto', metrics.mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14f3af07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MSE - Error Cuadratico Medio', 20.24827014789769)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'MSE - Error Cuadratico Medio', metrics.mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63886c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('RMSE - Raiz Error Cuadratico Medio', 4.499807790105894)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'RMSE - Raiz Error Cuadratico Medio', metrics.mean_squared_error(y_test, y_pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1eee629e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('R2 - Coeficiente de Determinacion', 0.7136297223659916)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'R2 - Coeficiente de Determinacion', metrics.r2_score(y_test, y_pred)  # para el testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f2464f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para el entrenamiento\n",
    "\n",
    "y_pred_train=linreg.predict(X_train)   # prediccion con datos conocidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b161cf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7423712239243331"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_train, y_pred_train)   # R2 para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a9d8a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.703315985520815"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(y_train, y_pred_train)**0.5  # RMSE para entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-banking",
   "metadata": {},
   "source": [
    "## Extra! Entrenando diferentes modelos a la vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "designed-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-momentum",
   "metadata": {},
   "source": [
    "### Almacenamos todos los modelos que vamos a entrenar en un diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "former-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "    'ridge': Ridge(),\n",
    "    'lasso': Lasso(),\n",
    "    'sgd': SGDRegressor(),\n",
    "    'knn': KNeighborsRegressor(),\n",
    "    'grad': GradientBoostingRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-pierce",
   "metadata": {},
   "source": [
    "### Iteramos sobre los modelos para entrenarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-cambridge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-novel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "based-mention",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "Leamos un poco la [documentación](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "\n",
    "**Wikipedia nos dice**            \n",
    "La validación cruzada o cross-validation es una técnica utilizada para evaluar los resultados de un análisis estadístico y garantizar que son independientes de la partición entre datos de entrenamiento y prueba. Consiste en repetir y calcular la media aritmética obtenida de las medidas de evaluación sobre diferentes particiones. Se utiliza en entornos donde el objetivo principal es la predicción y se quiere estimar la precisión de un modelo que se llevará a cabo a la práctica. Es una técnica muy utilizada en proyectos de inteligencia artificial para validar modelos generados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cellular-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las métricas para el cross validation son el R2 para regresión y el Accuracy para clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-walnut",
   "metadata": {},
   "source": [
    "![kfoldcv](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-affiliation",
   "metadata": {},
   "source": [
    "Cross-Validation: K-fold con 5 splits\n",
    "Lo que hacemos normalmente al entrenar el modelo es pasarle todos los registros y que haga el fit().      \n",
    "Con K-Folds -en este ejemplo de 5 splits- para entrenar, en vez de pasarle todos los registros directamente al modelo, haremos así:\n",
    "\n",
    "**Iterar 5 veces:**      \n",
    "- Apartaremos 1/5 de muestras\n",
    "- Entrenamos al modelo con el restante 4/5 de muestras\n",
    "- Mediremos el r2 obtenido sobre las que habíamos apartado.\n",
    "- Esto quiere decir que hacemos 5 entrenamientos independientes.\n",
    "- El R2 final será el promedio de las 5 R2 anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-reservation",
   "metadata": {},
   "source": [
    "### Hacemos CV a un solo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-payroll",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-louis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-advocacy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-harvey",
   "metadata": {},
   "source": [
    "### CV iterando por todos los modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-information",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "front-being",
   "metadata": {},
   "source": [
    "## Summmary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-opera",
   "metadata": {},
   "source": [
    "- Dividir dataset en entrenamiento / testeo para poder sacar métricas\n",
    "- La y es nuestra variable target que es la que queremos predecir\n",
    "- Siempre limpiamos y hacemos el preprocesado de los datos, tomamos decisiones con las filas que tengan valores nulos\n",
    "- Hay diferentes modelos de regresión, que se aproximan al mismo problema con diferentes fórmulas matemáticas\n",
    "- Dos grandes problemas -> clasificación y regresión. \n",
    "- Clasificación multiclass / multilabel "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clase",
   "language": "python",
   "name": "clase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
