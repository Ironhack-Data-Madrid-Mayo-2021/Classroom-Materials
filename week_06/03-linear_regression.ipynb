{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "confused-torture",
   "metadata": {},
   "source": [
    "# Regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-wilson",
   "metadata": {},
   "source": [
    "![memesitodeldía](../images/linear.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-chick",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Simple-linear-regression\" data-toc-modified-id=\"Simple-linear-regression-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Simple linear regression</a></span></li><li><span><a href=\"#Generamos-datos-para-explicar-de-forma-&quot;inversa&quot;-a-lo-visto-ayer-en-clase\" data-toc-modified-id=\"Generamos-datos-para-explicar-de-forma-&quot;inversa&quot;-a-lo-visto-ayer-en-clase-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Generamos datos para explicar de forma \"inversa\" a lo visto ayer en clase</a></span></li><li><span><a href=\"#Configuraciones-para-poner-mono-el-plot-de-seaborn\" data-toc-modified-id=\"Configuraciones-para-poner-mono-el-plot-de-seaborn-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Configuraciones para poner mono el plot de seaborn</a></span></li><li><span><a href=\"#¿Cómo-de-bueno-es-nuestro-modelo?\" data-toc-modified-id=\"¿Cómo-de-bueno-es-nuestro-modelo?-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>¿Cómo de bueno es nuestro modelo?</a></span></li><li><span><a href=\"#Calculamos-el-R2-del-modelo\" data-toc-modified-id=\"Calculamos-el-R2-del-modelo-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Calculamos el R2 del modelo</a></span></li><li><span><a href=\"#Regresión-lineal-con-sklearn\" data-toc-modified-id=\"Regresión-lineal-con-sklearn-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Regresión lineal con sklearn</a></span></li><li><span><a href=\"#Regresión-lineal-con-statsmodels\" data-toc-modified-id=\"Regresión-lineal-con-statsmodels-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Regresión lineal con statsmodels</a></span></li><li><span><a href=\"#Conceptos-del-OLS\" data-toc-modified-id=\"Conceptos-del-OLS-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Conceptos del OLS</a></span></li><li><span><a href=\"#Regresión-lineal-múltiple\" data-toc-modified-id=\"Regresión-lineal-múltiple-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Regresión lineal múltiple</a></span></li><li><span><a href=\"#Variables-categóricas\" data-toc-modified-id=\"Variables-categóricas-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Variables categóricas</a></span></li><li><span><a href=\"#Extensiones-del-modelo-lineal\" data-toc-modified-id=\"Extensiones-del-modelo-lineal-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Extensiones del modelo lineal</a></span><ul class=\"toc-item\"><li><span><a href=\"#Desafiando-la-suposición-aditiva:-la-sinergia\" data-toc-modified-id=\"Desafiando-la-suposición-aditiva:-la-sinergia-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>Desafiando la suposición aditiva: la sinergia</a></span></li></ul></li><li><span><a href=\"#Manos-a-la-obra\" data-toc-modified-id=\"Manos-a-la-obra-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Manos a la obra</a></span></li><li><span><a href=\"#Selección-de-modelo\" data-toc-modified-id=\"Selección-de-modelo-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Selección de modelo</a></span><ul class=\"toc-item\"><li><span><a href=\"#$R^2$-Ajustado\" data-toc-modified-id=\"$R^2$-Ajustado-13.1\"><span class=\"toc-item-num\">13.1&nbsp;&nbsp;</span>$R^2$ Ajustado</a></span></li></ul></li><li><span><a href=\"#Selección-por-pasos\" data-toc-modified-id=\"Selección-por-pasos-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Selección por pasos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Best-subset-selection\" data-toc-modified-id=\"Best-subset-selection-14.1\"><span class=\"toc-item-num\">14.1&nbsp;&nbsp;</span>Best subset selection</a></span></li><li><span><a href=\"#Modelo-nulo\" data-toc-modified-id=\"Modelo-nulo-14.2\"><span class=\"toc-item-num\">14.2&nbsp;&nbsp;</span>Modelo nulo</a></span></li><li><span><a href=\"#Forward-stepwise-selection\" data-toc-modified-id=\"Forward-stepwise-selection-14.3\"><span class=\"toc-item-num\">14.3&nbsp;&nbsp;</span>Forward stepwise selection</a></span></li></ul></li><li><span><a href=\"#Problemas-potenciales-en-la-regresión-lineal\" data-toc-modified-id=\"Problemas-potenciales-en-la-regresión-lineal-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>Problemas potenciales en la regresión lineal</a></span></li><li><span><a href=\"#Resumen\" data-toc-modified-id=\"Resumen-16\"><span class=\"toc-item-num\">16&nbsp;&nbsp;</span>Resumen</a></span></li><li><span><a href=\"#Further-Materials\" data-toc-modified-id=\"Further-Materials-17\"><span class=\"toc-item-num\">17&nbsp;&nbsp;</span>Further Materials</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualización\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "%matplotlib inline\n",
    "%config Inlinebackend.figure_format = 'retina'\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Librerías de modelado\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-therapy",
   "metadata": {},
   "source": [
    "## Simple linear regression\n",
    "\n",
    "Regresión lineal simple un modelo estadístico que supone una relación lineal entre un predictor y una variable objetivo. Matemáticamente, se puede expresar como:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-monthly",
   "metadata": {},
   "source": [
    "![formula](../images/formula.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-living",
   "metadata": {},
   "source": [
    "Si profundizamos un poco más, podemos encontrar esta otra expresión:\n",
    "\n",
    " $$ Y = \\beta_0 +  \\beta_1 X + \\epsilon$$\n",
    "\n",
    "Donde:\n",
    " * $X$ = variable predictora\n",
    " * $Y$ = variable objetivo\n",
    " * $\\beta_0$ = intercept\n",
    " * $\\beta_1$ = pendiente / slope\n",
    " * $\\epsilon$ = ruido (gaussiano)\n",
    "\n",
    "\n",
    "La ecuación anterior se conoce como *línea de regresión poblacional*.\n",
    "La línea de regresión lineal simple suele tener la forma que se muestra en la fórmula anterior, donde β0 y β1 son constantes desconocidas, que representan el intercepto y la pendiente de la línea de regresión, respectivamente.\n",
    "\n",
    "El intercepto es el valor de la variable dependiente (Y) cuando la variable independiente (X) tiene un valor de cero (0). La pendiente es una medida de la velocidad a la que cambia la variable dependiente (Y) cuando la variable independiente (X) cambia en uno (1). Las constantes desconocidas se denominan coeficientes o parámetros del modelo. Esta forma de la línea de regresión se conoce a veces como línea de regresión poblacional y, como modelo probabilístico, se ajusta al conjunto de datos de forma aproximada de ahí el uso del símbolo (≈) en la imagen. El modelo se denomina probabilístico porque no modela toda la variabilidad de la variable dependiente (Y) : El modelo se llama probabilístico porque no modela toda la variabilidad de la variable dependiente (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-monaco",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-turkish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hacíamos predicciones en base a una inferencia de beta_0 y beta_1 (m,n / pendiente, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Del ejemplo visto ayer en clase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-pontiac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-bangkok",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculábamos el error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-killing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-impact",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-magic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "impossible-height",
   "metadata": {},
   "source": [
    "## Generamos datos para explicar de forma \"inversa\" a lo visto ayer en clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Del ejemplo visto ayer en clase \n",
    "beta_0 = 10\n",
    "beta_1 = 0.08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-impression",
   "metadata": {},
   "source": [
    "Documentación de np.random normal --> https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html    \n",
    "Parámetros : \n",
    "- Media\n",
    "- Desviación estándar\n",
    "- Tamaño de la muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos las horas de estudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos las notas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos el dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-industry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "wanted-lodging",
   "metadata": {},
   "source": [
    "## Configuraciones para poner mono el plot de seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('poster')\n",
    "sns.set(rc={'figure.figsize': (16., 9.)})\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pintamos la línea de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-lodge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-mandate",
   "metadata": {},
   "source": [
    "Por supuesto, en la vida real no conocemos los verdaderos parámetros del modelo, ¡¡¡ni si el modelo es real!!! Hoy vamos a aprender una [valiosa lección](https://en.wikipedia.org/wiki/All_models_are_wrong):\n",
    "\n",
    "\n",
    "\n",
    "<center> <b>\"Todos los modelos son erróneos, pero algunos son útiles\"</b> </center>\n",
    "\n",
    "\n",
    "En la práctica lo que hacemos es, tras ver un gráfico de dispersión como el de arriba, intentar inferir los parámetros del modelo $\\beta_0$ y la pendiente, $\\beta_1$.  Una vez estimados, el ajuste estimado se convierte en $$ \\hat{Y} = \\hat{beta_0} + \\hat{beta_1} X$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-arrest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-paragraph",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-attitude",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a pintar la línea de regresión con el residuo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-anger",
   "metadata": {},
   "source": [
    "## ¿Cómo de bueno es nuestro modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-church",
   "metadata": {},
   "source": [
    "La diferencia numérica entre la *línea de regresión de mínimos cuadrados* y el valor real se llama *residuo* , y representa el error en la estimación: $e = y_i - \\hat{y}$.     \n",
    "La línea de regresión minimizó la *Suma de cuadrados residual* (RSS)     \n",
    "\n",
    "$$RSS = e_1^2 + e_2^2 + \\dots + e_n ^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-luther",
   "metadata": {},
   "source": [
    "Si sólo utilizamos la media como valor predicho para cada predicción, el error que cometeríamos es (*suma total de cuadrados*)\n",
    "\n",
    "$$TTS=\\Sigma(y_i - \\bar{y}_i)^2$$\n",
    "Consideremos esto nuestro punto de partida, hagamos una predicción y la ploteamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-container",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a meterlo en un dataframe para verlo más claro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-objective",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-massage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos TSS para el modelo anterior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-roulette",
   "metadata": {},
   "source": [
    "Recordemos que los coeficientes de la regresión lineal minimizan el $RSS=Sigma(y_i - \\hat{y_i})^2$, es decir, la cantidad de variabilidad que queda sin explicar después de realizar la regresión. El [coeficiente de determinación](https://en.wikipedia.org/wiki/Coefficient_of_determination):\n",
    "\n",
    "$$R^2 = \\frac{TSS -RSS}{TSS} = 1-\\frac{RSS}{TSS}$$\n",
    "\n",
    "mide la \"*proporción de variabilidad en Y que puede explicarse mediante X*\". Es una medida de la relación lineal que existe entre $X$ e $y$.\n",
    "\n",
    "**Nota:** en el caso de la regresión lineal simple, el coeficiente $R^2$ no es más que el cuadrado del coeficiente de correlación de *Pearson* que ya conocemos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-namibia",
   "metadata": {},
   "source": [
    "## Calculamos el R2 del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-lancaster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-constant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-miller",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-building",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-magic",
   "metadata": {},
   "source": [
    "$R^2$ mide lo bueno que es nuestro modelo de regresión. Cuanto más grande, mejor. Es un valor entre 0 y 1    \n",
    "**NOTA**: es computable para cualquier modelo, no importa si es lineal o no. Sólo se necesitan los valores reales y los predichos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-script",
   "metadata": {},
   "source": [
    "## Regresión lineal con sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-egyptian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-stuff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-romantic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-flight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-prison",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "conscious-kingdom",
   "metadata": {},
   "source": [
    "** Cálculo del error medio absoluto, del error medio cuadrático y del error medio cuadrático\n",
    "\n",
    "- **MAE** es el más fácil de entender, porque es el error medio.\n",
    "- **El MSE** es más popular que el MAE, porque el MSE \"castiga\" los errores más grandes, lo que suele ser útil en el mundo real.\n",
    "- **RMSE** es aún más popular que MSE, es la raíz cuadrada del MSE y mide la desviación estándar de los residuos.\n",
    "\n",
    "Todas estas son **funciones de pérdida**, porque queremos minimizarlas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-spanking",
   "metadata": {},
   "source": [
    "Lee más sobre MAE, MSE, RMSE Y R2 [AQUÍ](http://medium.com/analytics-vidhya/mae-mse-rmse-coefficient-of-determination-adjusted-r-squared-which-metric-is-better-cd0326a5697e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-albuquerque",
   "metadata": {},
   "source": [
    "## Regresión lineal con statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-values",
   "metadata": {},
   "source": [
    "Para no variar, un poquito de [documentación](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html)      \n",
    "Y [este artículo](https://jyotiyadav99111.medium.com/statistics-how-should-i-interpret-results-of-ols-3bde1ebeec01) que resume cómo interpretar la información del summary del OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-tongue",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "novel-portugal",
   "metadata": {},
   "source": [
    "## Conceptos del OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-amazon",
   "metadata": {},
   "source": [
    "-  <b>R2</b> : El coeficiente de determinación mide cuanta de la variación de 𝑦 es explicada por el modelo.\n",
    "Si la varianza de los errores o residuales 𝜎2𝑒 es cero, el modelo explica el 100% de la variable 𝑦. Si 𝜎2𝑒 es igual a la varianza de 𝑦 el modelo no explica nada y 𝑅2 vale cero.\n",
    "\n",
    "\n",
    "- <b>𝑅¯2 </b> : El coeficiente de correlación ajustado 𝑅¯2 corrige el valor de 𝑅2 por la cantidad de variables 𝑘 (igual a 2 para el caso analizado) y la cantidad de datos  𝑁\n",
    "\n",
    "- <b>P value </b> El p-valor para cada término comprueba la hipótesis nula de que el coeficiente es igual a cero (no tiene efecto). Un p-valor bajo (< 0.05) indica que puedes rechazar la hipótesis nula. ... Típicamente se utilizan los p-valores para determinar que téminos deben de mantenerse en el modelo de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-russell",
   "metadata": {},
   "source": [
    "## Regresión lineal múltiple\n",
    "\n",
    "Por supuesto, las horas que uno estudia no son el único factor importante para sacar buenas notas en el mundo real. Podemos pensar en el cociente intelectual, por ejemplo, como otro factor determinante. De hecho, podemos generalizar un modelo lineal para tener tantas variables como queramos:\n",
    "\n",
    " $$ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_2 X_m + \\epsilon$$\n",
    " \n",
    " En este caso lo que vamos a hacer, es añadir una variable que nos resta de la nota, las horas de fiesta.\n",
    " Imaginemos que por cada hora que salimos de fiesta mueren neuronas en nuestro cerebro y se nos olvida información, por tanto, nos restará nota (recordad que estamos inventando datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a crear el dataframe con las notas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-making",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-tokyo",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-tradition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-shower",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "popular-rachel",
   "metadata": {},
   "source": [
    "Los coeficientes de la regresión lineal múltiple se calculan de forma similar al caso de la regresión lineal simple: minimizan\n",
    "\n",
    "$$RSS = \\Sigma(y_i - \\hat{y_i})^2$$\n",
    "\n",
    "\n",
    "donde:\n",
    "\n",
    " $$ \\hat{y} = \\hat{beta_0} + \\hat{beta_1 X_1} + \\hat{beta_2} X_2 + \\hat + \\hat{\\beta_2} X_m$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-grove",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizamos los resultados con el OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-allah",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "secure-natural",
   "metadata": {},
   "source": [
    "## Variables categóricas\n",
    "\n",
    "Muy a menudo nos enfrentamos a situaciones en las que los predictores son de naturaleza *cualitativa*. Un buen ejemplo podría ser el sexo de una persona, que puede tomar los valores $M$ o $F$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-presentation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ¿Cómo trabajamos estas variables? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-catalog",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-information",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "connected-phase",
   "metadata": {},
   "source": [
    "Incluimos esta información en el modelo a través de una variable *dummy*:\n",
    "$$\n",
    "x_i= \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      1  \\quad \\text{si la persona es mujer} \\\\\n",
    "      0  \\quad \\text{si la persona es hombre} \\\\\n",
    "\\end{array} \n",
    "\\right. \n",
    "$$\n",
    "\n",
    "\n",
    "Si esta es nuestra única variable, esto resulta en un modelo:\n",
    "\n",
    "$$y_i = \\beta_0 + \\beta_1 x_i +\\epsilon_i = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      \\beta_0 + \\beta_1 +\\epsilon_i  \\quad \\text{si la persona es mujer} \\\\\n",
    "      \\beta_0 + \\epsilon_i  \\quad \\text{si la persona es hombre} \\\\\n",
    "\\end{array} \n",
    "\\right.  $$\n",
    "\n",
    "En este caso, $\\beta_0$ representa la nota media de los hombres, y $\\beta_0 + \\beta_1$ la nota media de las mujeres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-scheduling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acquired-steps",
   "metadata": {},
   "source": [
    "## Extensiones del modelo lineal\n",
    "\n",
    "Hay varios supuestos que se utilizan al ajustar un modelo lineal. \n",
    "* Los errores se distribuyen normalmente y tienen una varianza constante\n",
    "* Los errores no están correlacionados entre sí\n",
    "* **Supuesto aditivo** El efecto de los cambios en un predictor $X_j$ sobre la respuesta $Y$ es independiente de los valores de los otros predictores.\n",
    "* **Supuesto lineal** El cambio en la respuesta para un aumento de una unidad en $X_j$ es el mismo sin importar el valor de $X_j$.\n",
    "\n",
    "### Desafiando la suposición aditiva: la sinergia\n",
    "\n",
    "A veces nuestras variables tendrán interacciones naturales. Por ejemplo, podemos pensar que cuanto más se escuchen nuestros anuncios en la radio, más eficaces serán nuestros anuncios en la televisión. Es decir, el efecto de ambos es *mayor* (o *menor*) que la suma de las partes.\n",
    "\n",
    "Este es un tema comúnmente estudiado en [marketing](https://smallbusiness.chron.com/definition-synergy-marketing-21786.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv = pd.read_csv('../datasets/Advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-commonwealth",
   "metadata": {},
   "source": [
    "## Manos a la obra\n",
    "* Crear tres modelos independientes de regresión lineal simple\n",
    "    * Interpretar los resultados\n",
    "* Crear un modelo multivariante con los tres predictores\n",
    "    * Interpretar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-patent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-depth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-baghdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-madagascar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-tourism",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-inventory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-relations",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-ireland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cordless-knock",
   "metadata": {},
   "source": [
    "La diferencia es que la covarianza nos da la dirección (positiva o negativa) entre las variables y la correlación nos da esto más la fuerza de esta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-quarter",
   "metadata": {},
   "source": [
    "Recuerde el **principio jerárquico:**\n",
    "\n",
    "\"*Si incluimos una interacción en un modelo, debemos incluir también los efectos principales, incluso si los valores p que se asocian a sus coeficientes no son significativos*\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-cleaning",
   "metadata": {},
   "source": [
    "## Selección de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-saturday",
   "metadata": {},
   "source": [
    "###  $R^2$ Ajustado \n",
    "Hay una cosa curiosa con $R^2$. ¡¡Mira lo que pasa cuando incluimos variables *al azar*!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-shepherd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-cannon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-receiver",
   "metadata": {},
   "source": [
    "El coeficiente `Adj. R-cuadrado` pretende penalizar el $R^2$ de un modelo cuando se incluyen *demasiadas* varaibles. \n",
    "$$\\bar R^2 = 1-(1-R^2){n-1 \\ sobre n-p-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-participation",
   "metadata": {},
   "source": [
    "## Selección por pasos\n",
    "Siempre hay que intentar tener un modelo lo más sencillo posible. Habrá otras formas de hacerlo utilizando la **regularización**, veremos más adelante cómo hay librerías que nos ayudarán a decidir si nos quedamos con unas u otras variabless, pero hasta ahora los métodos que describimos aquí son bastante útiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-wallet",
   "metadata": {},
   "source": [
    "### Best subset selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-constant",
   "metadata": {},
   "source": [
    "El proceso de best subset selection consiste en evaluar todos los posibles modelos que se pueden crear por combinación de los predictores disponibles. El algoritmo a seguir para k predictores es:\n",
    "\n",
    "- Se genera lo que se conoce como modelo nulo (M0), que es el modelo sin ningún predictor.\n",
    "\n",
    "- Se generan todos los posibles modelos que contienen un único predictor y se selecciona el que tiene menor error de entrenamiento. Al modelo seleccionado se denomina (M1).\n",
    "\n",
    "- Se repite el paso anterior para modelos con dos predictores y así sucesivamente hasta llegar al modelo con todos los predictores (Mk).\n",
    "\n",
    "- De entre los mejores modelos seleccionados para cada número de predictores (M0, M1, M2,…,Mk) se identifica el mejor modelo, esta vez empleando una métrica de validación (R2 Ajustado).     \n",
    "\n",
    "A pesar de que este método explora todas las posibilidades, tiene dos limitaciones fundamentales:\n",
    "Requerimientos computacionales: Se requiere calcular 2p modelos distintos, lo que lo hace inviable para más de 40 predictores.\n",
    "Problemas de overfitting. Al generarse tantos modelos, por simple azar se pueden encontrar buenos resultados. Por esta razón best subset selection no se ecominda si hay más de 10 predictores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-practice",
   "metadata": {},
   "source": [
    "### Modelo nulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-museum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-violence",
   "metadata": {},
   "source": [
    "### Forward stepwise selection\n",
    "\n",
    "Forward stepwise selection es una alternativa computacionalmente más eficiente que best subset selection, en la que no se evalúan todas las posibles combinaciones de predictores sino solo un subconjunto. El proceso se inicia generando el modelo nulo (M0) sin predictores. A continuación, se generan todos los posibles modelos que se pueden crear añadiendo un predictor al modelo nulo. De entre todos estos modelos con 1 predictor se selecciona el mejor basándose en el error de entrenamiento, al modelo elegido se denomina M1. Se repite el paso anterior, pero esta vez partiendo del último modelo seleccionado y así sucesivamente hasta llegar al modelo con todos los predictores. De entre los mejores modelos seleccionados para cada número de predictores (M0, M1, M2,…,Mk), se identifica el mejor, esta vez empleando una métrica de validación (validación cruzada, Cp, AIC, BIC o R2ajustado).\n",
    "\n",
    "Al crear modelos anidados, en los que el modelo k se construye a partir del modelo k−1, el método forward stepwise selection no garantiza que se seleccione el mejor modelo de entre todos los posibles, ya que no se evalúan todas las posibles combinaciones. Sin embargo, suele llegar a modelos óptimos consiguiendo un buen rendimiento computacional y evitando el overfitting. Otra ventaja añadida es que, forward stepwise selection puede emplearse incluso cuando el número de predictores es mayor que el de observaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-institution",
   "metadata": {},
   "source": [
    "Primero:  \n",
    "1. Todos los modelos con una sola variable. Uno gana. Ganador A\n",
    "2. Añade a este modelo todas las variables, una por una. Uno gana. Ganador B \n",
    "3. Añade a este modelo todas las variables, una por una. Uno gana. Ganador C\n",
    "...\n",
    "...\n",
    "\n",
    "FIN: tomar el ganador entre A, B, C, D...\n",
    "\n",
    "Si R2 tiene dos decimales iguales, consideramos el modelo con más variables representativas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-province",
   "metadata": {},
   "source": [
    "## Problemas potenciales en la regresión lineal\n",
    "\n",
    "Los principales supuestos de un modelo lineal son:\n",
    "\n",
    "* Los datos son lineales \n",
    "* Los errores no están correlacionados\n",
    "* La varianza de los términos de error es constante\n",
    "\n",
    "¿Qué ocurre si no se cumplen estos supuestos? \n",
    "\n",
    "Además, nuestros modelos pueden sufrir otros problemas como:\n",
    "* Valores atípicos\n",
    "* Puntos de apalancamiento elevados\n",
    "* Colinealidad\n",
    "* Valores perdidos\n",
    "\n",
    "Ved este [vídeo](https://www.youtube.com/watch?v=hVe2F9krrWk) para una introducción al tema.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-invasion",
   "metadata": {},
   "source": [
    "Estos cuatro conjuntos de datos son distintos, pero resulta que tienen la misma media aritmética y varianza de los valores x e y, la misma correlación, el mismo coeficiente de correlación y la misma recta de regresión. algunos con 2 ó 3 decimales. Son el Cuarteto de Anscombe, llamado así por F.J. Anscombe, un matemático estadista que los publicó en 1973. Se suelen utilizara para enseñar que además de calcular las propiedades estadística de los datos, conviene visualizarlos.\n",
    "\n",
    "En todos los casos las representaciones nos dicen algo más sobre los datos: los primeros parecen un tanto aleatorios pero relacionados, los segundos muestran un patrón claro pero notablemente diferente; en el tercero y el cuarto hay otros patrones enturbiados por algunos valores anómalos. Estos valores pueden ser errores, datos reales que simplemente están fuera de lo normal o incluso datos producidos artificialmente para que todo encaje.\n",
    "\n",
    "Moraleja: no te fíes ciegamente de los datos y tampoco de las estadísticas que obtenga de ellos; procura montar además una visualización para entenderlos.\n",
    "![anscombe](../images/anscombe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-nancy",
   "metadata": {},
   "source": [
    "Echa un ojo a [Wikipedia](https://en.wikipedia.org/wiki/Anscombe%27s_quartet) que dice que:       \n",
    "El cuarteto de Anscombe consta de cuatro conjuntos de datos que tienen estadísticas descriptivas simples casi idénticas, pero que tienen distribuciones muy diferentes y aparecen de forma muy distinta cuando se grafican. Cada conjunto de datos consta de once puntos (x,y). Fueron construidos en 1973 por el estadístico Francis Anscombe para demostrar tanto la importancia de graficar los datos antes de analizarlos como el efecto de los valores atípicos y otras observaciones influyentes en las propiedades estadísticas. Describió el artículo como un intento de contrarrestar la impresión entre los estadísticos de que \"los cálculos numéricos son exactos, pero los gráficos son toscos\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-crime",
   "metadata": {},
   "source": [
    "## Resumen "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-shuttle",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "competitive-enough",
   "metadata": {},
   "source": [
    "## Further Materials \n",
    "\n",
    "* One example of [linear regression with the Boston data set](https://towardsdatascience.com/linear-regression-on-boston-housing-dataset-f409b7e4a155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-formula",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-location",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-consensus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
